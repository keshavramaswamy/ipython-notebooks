{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA - Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import lifelines\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Closest match from list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_crimes = list(set(list_crimes))\n",
    "import difflib\n",
    "for index,word in enumerate(list_crimes):\n",
    "    print word,':',difflib.get_close_matches(word, list_crimes[index+1:],20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Name Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distict_code_name_map = {\n",
    "'A1' : 'Downtown','A15' : 'Charlestown','A7' :'East Boston',\n",
    "'B2' : 'Roxbury',\n",
    "'B3' : 'Mattapan',\n",
    "'C6' : 'South Boston',\n",
    "'C11' : 'Dorchester',\n",
    "'D4' : 'South End',\n",
    "'D14' : 'Brighton',\n",
    "'E5' :'West Roxbury',\n",
    "'E13' : 'Jamaica Plain',\n",
    "'E18': 'Hyde Park',\n",
    "'HTU': 'Human Traffic Unit'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If - Else List Comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_hours = list()\n",
    "for row in df_boston.times:\n",
    "    list_hours \n",
    "    if 'AM' in row:\n",
    "        list_hours.append(int(row.split(':',1)[0]))\n",
    "    else:\n",
    "        list_hours.append(int(row.split(':',1)[0]) + 12 )\n",
    "df_boston['hours'] = pd.Series(list_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_hours = [ int(row.split(':',1)[0]) if 'AM' in row else int(row.split(':',1)[0]) + 12 for row in df_boston.times]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = ''.join(chr(index) if index in ords_to_keep else replace_with\n",
    "                for index in xrange(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If List Comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputlist = []\n",
    "for y in a:\n",
    "    if y not in b:\n",
    "        outputlist.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputlist = [y for y in a if y not in b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Multiple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_boston = df_boston.drop(['compnos','naturecode'],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### IPython AutoTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%install_ext https://raw.github.com/cpcloud/ipython-autotime/master/autotime.py\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [i for i in range(0,100)]\n",
    "x.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proportion of Not-Null values for Series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(df_gtd.approxdate.notnull()) / float(len(df_gtd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove those features with more than x % null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in df_gtd.columns:\n",
    "    rate = sum(df_gtd[col].notnull())/float(len(df_gtd)) * 100\n",
    "    if rate < 1:\n",
    "        df_gtd = df_gtd.drop(col,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing Missing Values: \n",
    "Columns of datatype object are replaced by the most frequent value while the missing values in the column of other datatypes are replaced by their median.\n",
    "Source: http://stackoverflow.com/questions/25239958/impute-categorical-missing-values-in-scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        \"\"\"Impute missing values.\n",
    "        Columns of dtype object are imputed with the most frequent value \n",
    "        in column.\n",
    "        Columns of other types are imputed with median of column.\n",
    "        \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].median() for c in X],\n",
    "            index=X.columns)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save dataframe to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Saving these to pickle\n",
    "df_gtd.to_pickle('df_gtd.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Animated Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The animated plotting is used from Jake's post on embedding animated plots in IPython notebooks:\n",
    "http://jakevdp.github.io/blog/2013/05/12/embedding-matplotlib-animations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import animation, pyplot as plt\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "VIDEO_TAG = \"\"\"<video controls autoplay>\n",
    " <source src=\"data:{0}\">\n",
    " Your browser does not support the video tag.\n",
    "</video>\"\"\"\n",
    "\n",
    "def anim_to_html(anim):\n",
    "    if not hasattr(anim, '_encoded_video'):\n",
    "        with NamedTemporaryFile(suffix='.m4v') as f:\n",
    "            anim.save(f.name, fps=20, extra_args=['-vcodec', 'libx264', '-pix_fmt', 'yuv420p'])\n",
    "            video = open(f.name, \"rb\").read()\n",
    "        anim._encoded_video = 'video/mp4;base64,' + video.encode(\"base64\")\n",
    "    # prevent figure displayed as a PNG below the animation\n",
    "    plt.close()\n",
    "    \n",
    "    return VIDEO_TAG.format(anim._encoded_video)\n",
    "\n",
    "animation.Animation._repr_html_ = anim_to_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "import random\n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    return line,\n",
    "\n",
    "def calc_parameters(i):\n",
    "    alpha_param = 81\n",
    "    beta_param = 219\n",
    "    for j in range(0,i):\n",
    "        if l[j] is 'H':\n",
    "            alpha_param = alpha_param + 1\n",
    "        else:\n",
    "            beta_param =  beta_param + 1    \n",
    "    return alpha_param, beta_param\n",
    "\n",
    "def animate(i):\n",
    "    alpha_param, beta_param = calc_parameters(i)\n",
    "    if l[i] is 'H':\n",
    "        alpha_param = alpha_param + 1\n",
    "    else:\n",
    "        beta_param =  beta_param + 1\n",
    "    beta_dist = beta(alpha_param, beta_param)\n",
    "    y = beta_dist.pdf(x)\n",
    "    line.set_data(x, y)\n",
    "    return line,alpha_param, beta_param\n",
    "\n",
    "def randomly(seq):\n",
    "    shuffled = list(seq)\n",
    "    random.shuffle(shuffled)\n",
    "    return shuffled\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(xlim=(0.15, 0.45), ylim = (0,26))\n",
    "x = np.linspace(0,1,600)\n",
    "alpha_param, beta_param = calc_parameters(0)\n",
    "beta_dist = beta(alpha_param, beta_param)\n",
    "\n",
    "y = beta_dist.pdf(x)\n",
    "line, = ax.plot(x, y, lw=2, label='beta_posterior')\n",
    "legend = ax.legend(loc='upper right', shadow=True, fontsize='x-small')\n",
    "l = randomly('H'* 200 + 'T' * 400)\n",
    "list_means = []\n",
    "    \n",
    "animation.FuncAnimation(fig, animate, init_func=init, frames=600, interval=20, blit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape and store in DataFrame - Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_data(page_count):\n",
    "    \"\"\"\n",
    "    scrapes the required data present in the form of a table from the given url\n",
    "    :param url: page of the ESPNCricinfo Stats URL query\n",
    "    :return: the raw unicode text\n",
    "    \"\"\"\n",
    "    url = statsguru_query_url\n",
    "    complete_url = url.partition('page=1')[0] + \"page=\" + str(page_count) + url.partition('page=1')[-1]\n",
    "    r = requests.get(complete_url)\n",
    "    data = r.text\n",
    "    soup = BeautifulSoup(data)\n",
    "    table = soup.find_all('table')\n",
    "    return table[2].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming data - Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    \"\"\"\n",
    "    scrapes the data, cleans it and transforms the data to load into a pandas dataframe\n",
    "    \"\"\"\n",
    "    page_count = 12\n",
    "    df = pd.DataFrame()\n",
    "    get_list_columns = lambda text, start_index, end_index: [str(unicode_text)\n",
    "                                                                for unicode_text in text][start_index:end_index]\n",
    "    get_data_rows = lambda text, start_index: text[start_index:]\n",
    "    remove_all_occurences = lambda data, item: [x for x in data if x != item]\n",
    "    get_list_rows = lambda data: [data[index: index + 13] for index, row in enumerate(data) if index % 13 == 0]\n",
    "    for page in range(1, page_count + 1):\n",
    "        raw_text = scrape_data(page)\n",
    "        clean_text = clean_data(raw_text)\n",
    "        list_columns = get_list_columns(clean_text, 3, 16)\n",
    "        data_rows = get_data_rows(clean_text, 16)\n",
    "        data_rows = remove_all_occurences(data_rows, u'')\n",
    "        list_rows = get_list_rows(data_rows)\n",
    "        df_new = pd.DataFrame(list_rows, columns=list_columns)\n",
    "        if len(df) == 0:\n",
    "            df = df_new\n",
    "        else:\n",
    "            df = pd.concat([df, df_new])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lambda Function - Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calc_career_length = lambda df: [row.career_end_date - row.career_start_date + 1 for index, row in df.iterrows()]\n",
    "df_span['career_length'] = calc_career_length(df_span)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace null with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_boston.fillna(0.0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove rows whose column equal to particular value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_boston = df_boston[df_boston.latitudes != 0.0]\n",
    "df_boston = df_boston[df_boston.longitudes != 0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Set pandas show all columns in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GroupBy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "     return Series(dict(Number_of_tweets = x['content'].count(), \n",
    "                        Company=x['Company'].min(),\n",
    "                        Description=x['from_user_description'].min(),\n",
    "                        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "account_count = df.groupby('from_user_screen_name').apply(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### adding data to sqlite in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine # database connection\n",
    "disk_engine = create_engine('sqlite:///311_8M.db') # Initializes database with filename 311_8M.db in current directory\n",
    "start = dt.datetime.now()\n",
    "chunksize = 20000\n",
    "j = 0\n",
    "index_start = 1\n",
    "\n",
    "for df in pd.read_csv('311_100M.csv', chunksize=chunksize, iterator=True, encoding='utf-8'):\n",
    "    \n",
    "    df = df.rename(columns={c: c.replace(' ', '') for c in df.columns}) # Remove spaces from columns\n",
    "\n",
    "    df['CreatedDate'] = pd.to_datetime(df['CreatedDate']) # Convert to datetimes\n",
    "    df['ClosedDate'] = pd.to_datetime(df['ClosedDate'])\n",
    "\n",
    "    df.index += index_start\n",
    "\n",
    "    # Remove the un-interesting columns\n",
    "    columns = ['Agency', 'CreatedDate', 'ClosedDate', 'ComplaintType', 'Descriptor',\n",
    "               'CreatedDate', 'ClosedDate', 'TimeToCompletion',\n",
    "               'City']\n",
    "\n",
    "    for c in df.columns:\n",
    "        if c not in columns:\n",
    "            df = df.drop(c, axis=1)    \n",
    "\n",
    "    \n",
    "    j+=1\n",
    "    print '{} seconds: completed {} rows'.format((dt.datetime.now() - start).seconds, j*chunksize)\n",
    "\n",
    "    df.to_sql('data', disk_engine, if_exists='append')\n",
    "    index_start = df.index[-1] + 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
